{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9f325-7f64-40bc-ab94-d1a9992a3f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Building a system that handles rule-based (dictionary/ontology) and LLM-based (embeddings, semantic search) approaches, \n",
    "ensuring it scales effectively and delivers high-quality matches\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db41c8f-9710-407e-ad66-65c8daea30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation Plan\n",
    "#Install Required Libraries:\n",
    "\n",
    "#pip install spacy sentence-transformers faiss-cpu flask\n",
    "#Optional: pandas, numpy for structured data handling, and gunicorn for deployment.\n",
    "'''\n",
    "Structure:\n",
    "\n",
    "Preprocessing: Normalize inputs.\n",
    "Rule-Based Matching: Use dictionaries or regex for exact matches.\n",
    "LLM-Based Matching: Use Sentence-BERT for semantic search.\n",
    "Integration: Combine scores for hybrid results.\n",
    "API Interface: Flask for query submission and results retrieval.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaacc41-8d67-4ad4-a1c4-9dc12c17c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Initialize components\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Rule-based dictionary (example)\n",
    "RULE_BASED_DICT = {\n",
    "    \"education\": [\"school\", \"university\", \"teaching\"],\n",
    "    \"artificial intelligence\": [\"AI\", \"machine learning\", \"deep learning\"],\n",
    "}\n",
    "\n",
    "# Sample dataset for semantic search\n",
    "DATASET = [\n",
    "    {\"id\": 1, \"text\": \"AI tools for teaching and learning.\"},\n",
    "    {\"id\": 2, \"text\": \"Best practices in university-level education.\"},\n",
    "    {\"id\": 3, \"text\": \"Machine learning models for beginners.\"},\n",
    "]\n",
    "# Generate embeddings for the dataset\n",
    "DATASET_TEXTS = [entry[\"text\"] for entry in DATASET]\n",
    "DATASET_EMBEDDINGS = embedding_model.encode(DATASET_TEXTS, convert_to_tensor=False)\n",
    "\n",
    "# Create FAISS index\n",
    "embedding_dim = DATASET_EMBEDDINGS.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(np.array(DATASET_EMBEDDINGS))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop])\n",
    "\n",
    "# Rule-based matching\n",
    "def rule_based_match(query):\n",
    "    query_terms = set(query.split())\n",
    "    matched_rules = {\n",
    "        key: [term for term in value if term in query_terms]\n",
    "        for key, value in RULE_BASED_DICT.items()\n",
    "        if any(term in query_terms for term in value)\n",
    "    }\n",
    "    return matched_rules\n",
    "\n",
    "# LLM-based matching\n",
    "def llm_based_match(query, top_k=3):\n",
    "    query_embedding = embedding_model.encode(query, convert_to_tensor=False)\n",
    "    distances, indices = index.search(np.array([query_embedding]), top_k)\n",
    "    results = [\n",
    "        {\"id\": DATASET[idx][\"id\"], \"text\": DATASET[idx][\"text\"], \"score\": 1 - dist}\n",
    "        for idx, dist in zip(indices[0], distances[0])\n",
    "    ]\n",
    "    return results\n",
    "\n",
    "# Hybrid matching\n",
    "def hybrid_match(query, rule_weight=0.6, llm_weight=0.4, top_k=3):\n",
    "    query = preprocess(query)\n",
    "    \n",
    "    # Rule-based matching\n",
    "    rule_matches = rule_based_match(query)\n",
    "    rule_score = len(rule_matches) * rule_weight  # Example scoring logic\n",
    "\n",
    "    # LLM-based matching\n",
    "    llm_matches = llm_based_match(query, top_k)\n",
    "    llm_score = sum(match[\"score\"] for match in llm_matches) / len(llm_matches) * llm_weight\n",
    "\n",
    "    # Combined score\n",
    "    combined_score = rule_score + llm_score\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"rule_matches\": rule_matches,\n",
    "        \"llm_matches\": llm_matches,\n",
    "        \"combined_score\": combined_score,\n",
    "    }\n",
    "\n",
    "# API Endpoint\n",
    "@app.route(\"/match\", methods=[\"POST\"])\n",
    "def match():\n",
    "    data = request.json\n",
    "    query = data.get(\"query\", \"\")\n",
    "    if not query:\n",
    "        return jsonify({\"error\": \"Query is required\"}), 400\n",
    "\n",
    "    results = hybrid_match(query)\n",
    "    return jsonify(results)\n",
    "\n",
    "# Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49dc94-a285-486f-a86e-4380f98430ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How It Works\n",
    "#Preprocessing:\n",
    "'''\n",
    "Lemmatizes and removes stopwords from the query for cleaner inputs.\n",
    "Rule-Based Matching:\n",
    "\n",
    "Uses a predefined dictionary to detect exact or close matches.\n",
    "LLM-Based Matching:\n",
    "\n",
    "Converts the query and dataset into embeddings using SentenceTransformer.\n",
    "Performs semantic search with FAISS.\n",
    "Hybrid Scoring:\n",
    "\n",
    "Combines the rule-based and LLM-based scores with weights for flexibility.\n",
    "API Endpoint:\n",
    "\n",
    "Exposes a /match endpoint for users to submit queries and receive results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6161699-fc1d-42b0-b07c-67eb8becf906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Usage\n",
    "#Start the server:\n",
    "python app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea1278-2e1c-49f7-8693-eabcf679b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send a query (using Postman, Curl, or similar):\n",
    "curl -X POST http://127.0.0.1:5000/match -H \"Content-Type: application/json\" -d '{\"query\": \"AI software for education\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8c076-4b34-492a-9443-655e27b00f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Response:\n",
    "{\n",
    "  \"query\": \"ai software education\",\n",
    "  \"rule_matches\": {\n",
    "    \"artificial intelligence\": [\"AI\"],\n",
    "    \"education\": [\"education\"]\n",
    "  },\n",
    "  \"llm_matches\": [\n",
    "    {\"id\": 1, \"text\": \"AI tools for teaching and learning.\", \"score\": 0.92},\n",
    "    {\"id\": 2, \"text\": \"Best practices in university-level education.\", \"score\": 0.87},\n",
    "    {\"id\": 3, \"text\": \"Machine learning models for beginners.\", \"score\": 0.80}\n",
    "  ],\n",
    "  \"combined_score\": 0.83\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891dcd4a-84df-416b-bf56-b873da289994",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Scalability Enhancements\n",
    "Use Gunicorn or uWSGI for production deployment.\n",
    "Store embeddings and rules in a database (PostgreSQL, MongoDB).\n",
    "Scale FAISS with distributed systems like Milvus or Weaviate.\n",
    "Fine-tune the embedding model for domain-specific data.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
